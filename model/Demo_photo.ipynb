{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the Project<br>\n",
    "\n",
    "This is a demo for the project which is gonna demonstrate the main functions of the project. <br>\n",
    "The project is focused on the detection and recognition of traffic signs. <br>\n",
    "Let's see how it functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we have to do is importing everything that is necessary for the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various imports\n",
    "from Model import ModelCNN as Classifier\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2 as Detector\n",
    "#from torchvision.models.detection import ssd300_vgg16 as Detector\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from GTSDB_Dataset import GTSDB_Dataset as Dataset\n",
    "from torch.utils.data import Subset\n",
    "from __global__  import *\n",
    "from torchvision.transforms import v2\n",
    "import cv2 as cv\n",
    "from TaT_Detection_FastRCNN import test_model\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from dic_signals import classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comfort let's also define these two costants that we will use later. These two constants are used to represent the rows and the columns that we're gonna have in the plots where we display our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_SAMPLE_C = 3\n",
    "NUM_SAMPLE_R = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's setup the device, we prefer the gpu's cuda for efficiency but if it isn't available the only choice is to use the cpu. <br>\n",
    "\n",
    "We also defined seq, which is a series of trasformations we will apply to the images once they've been opened. The trasformation are mainly for neural network usage, the only thing we are doing is converting to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare images for elaboration\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu') #selecting the device\n",
    "seq = v2.Compose([\n",
    "        v2.ToImage(), #converting to tensor image\n",
    "        v2.ToDtype(torch.float32, scale=True)  \n",
    "    ]) #trasformation that the images will undergo when used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to load the dataset. In this case we load the dataset two times: the first one is loaded with trasformations, so all images will be trasformated according to the instructions in \"seq\", the second one is raw, so without trasformations. <br>\n",
    "This because the modified one is used for training and testing, while the second one is used for showing purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = Dataset(IMGS_PATH_TEST_GTSDB, transform=seq) #dataset of the images\n",
    "data_raw = Dataset(IMGS_PATH_TEST_GTSDB) #dataset of the images without trasformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is load, we have to choose some images so we can do detection and recognition, we choose it randomly. <br>\n",
    "After choosing the images we load it using the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose random images\n",
    "\n",
    "test_images = [] #list of the test images\n",
    "\n",
    "sub = [random.randint(0, len(data)) for i in range(NUM_SAMPLE_C * NUM_SAMPLE_R)] #random choosing images\n",
    "dataLoader = DataLoader( Subset(data, sub), batch_size=1, shuffle=False) #declaring dataloader that load subset of dataset images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing the detection and recognition, let's view the images. We show them via plotting to a plot structured in rows and columns. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting box images\n",
    "\n",
    "fig = plt.figure(figsize=(128, 200)) #setting the size of the figure to plot to 32x32\n",
    "rows, cols = NUM_SAMPLE_C, NUM_SAMPLE_R #defining number of columns and rows\n",
    "\n",
    "y = 0\n",
    "for i in range(1, rows * cols + 1): \n",
    "    \n",
    "    random_img, name = data_raw.__getitem__(sub[ min(y, NUM_SAMPLE_C * NUM_SAMPLE_R - 1) ]) #getting images\n",
    "    y = y + 1\n",
    "    test_images.append(random_img) #appending images to the plot\n",
    "    fig.add_subplot(rows, cols, i) #\n",
    "    plt.imshow(random_img) #showing image to the plot\n",
    "    plt.title(name) #title of image\n",
    "    plt.axis(False) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the detection and detection and recognition, we need two neural network, one for the detection and the other for recognition. <br>\n",
    "So we create these two and load weights into them. We're setting them to evaluation mode and passing to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model models\n",
    "\n",
    "detector = Detector() #declaring the detector\n",
    "detector.load_state_dict( \n",
    "    torch.load('saved_model/FastRCNN/pesi_ok/model_weights.pth')\n",
    "    #torch.load('saved_model/ssd300/pesi_ok/model_weights.pth')\n",
    ") #loading weigths into the model\n",
    "\n",
    "\n",
    "#declaring the classifier\n",
    "classifier = Classifier(input_channels=3, input_shape=48, hidden_units=96, output_shape=43)\n",
    "#loading the weights on the classifier\n",
    "classifier.load_state_dict(torch.load('saved_model/CNNModel/pesi_ok/model_weights.pth')) \n",
    "\n",
    "\n",
    "classifier.eval() #setting the classifier to evaluation mode\n",
    "detector.eval() #setting the detector to evaluation mode\n",
    "classifier.to(device) #passing the classifier to device\n",
    "detector.to(device) #passing the detector to device\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the trasformations that the images will undergo before the detection. <br>\n",
    "Other than converting to tensor so we can use it in the neural networks, we resize the images to 48x48 and apply some contrast for more clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounded = [] #images already done\n",
    "\n",
    "#trasformation that the image will undergo when opened\n",
    "pp = v2.Compose(\n",
    "    [   \n",
    "        v2.ToImage(), #converting to tensor image\n",
    "        v2.ToDtype(dtype=torch.float32), #converting to dTyppe\n",
    "        Resize((48, 48), interpolation=InterpolationMode.NEAREST_EXACT), #resizing image to 48x48\n",
    "        v2.RandomAutocontrast(p=1.0), #applying contrast   \n",
    "           \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bounded = [] #images already done\n",
    "\n",
    "dict_r = test_model(detector, dataLoader, th=0.60, device=device) #doing the test and getting results\n",
    "for i, d in enumerate(dict_r):\n",
    "    signals = torch.Tensor([]).to(device) #create tensor and pass it the device\n",
    "    img = test_images[i]\n",
    "    \n",
    "    for box in d['boxes']:\n",
    "        \n",
    "        signal = img[box[1]:box[3], box[0]:box[2], :] #getting the sign\n",
    "        # print( signal.shape)\n",
    "        signal = pp(signal).unsqueeze(0) #.permute( (2, 0, 1) ) #doing the unsqueeze for the image\n",
    "        # print( signal.shape)\n",
    "        signals = torch.cat( (signals, signal.to(device)), dim=0 )\n",
    "        #signals.append(signal.to(device))\n",
    "\n",
    "\n",
    "    \n",
    "    # print(\"signals :\", signals.shape)\n",
    "    if signals.numel() == 0: #if tensor is empty\n",
    "        bounded.append(img)\n",
    "        continue \n",
    "\n",
    "\n",
    "    x = classifier(signals) #giving the image to the classifier and getting the result\n",
    "    signals_dected = x.argmax(dim=1) #getting the max value\n",
    "    # print(signals_dected.shape)\n",
    "\n",
    "    for idx, box in enumerate(d['boxes']):\n",
    "        img = cv.rectangle(img, (box[0], box[1]), (box[2], box[3]), color=(0, 255, 0))#drawing the box around the sign\n",
    "        #putting the label to the box drawed\n",
    "        value = signals_dected[idx].cpu().numpy().item()\n",
    "       \n",
    "        img = cv.putText(img, f'Label: {classes[value]}', (box[0] - 10, box[1] - 10),  fontFace=cv.FONT_ITALIC, fontScale=0.4, color=(0,255,0))\n",
    "\n",
    "   \n",
    "    bounded.append(img) #append the already processed image\n",
    "    \n",
    "       \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(128, 200)) #defining the size of each figure in the plot\n",
    "rows, cols = NUM_SAMPLE_C, NUM_SAMPLE_R # number of rows and columns\n",
    "y = 0\n",
    "for i in range(1, rows * cols + 1):\n",
    "    fig.add_subplot(rows, cols, i) #creating the subplot\n",
    "    plt.imshow(bounded[min(y, len(bounded) - 1)]) #showing the image in the plot\n",
    "    plt.axis(False)\n",
    "    y += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
